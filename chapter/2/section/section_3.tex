\section{Procesamiento de lenguaje natural}\label{sec:procesamiento_lenguaje_natural}

El procesamiento de lenguaje natural o \textit{Natural Language Processing} (NLP) es un campo que se sitúa en la
intersección de la informática, la inteligencia artificial y la lingüística.

Se dedica al desarrollo de sistemas que permiten a las computadoras entender y generar lenguaje humano de una manera
útil.
La historia del NLP comienza en la década de 1950, marcada por el trabajo pionero de Alan Turing y su famoso
test de Turing, que planteaba la cuestión de si una máquina puede emular el lenguaje humano de manera convincente
~\cite{article_touring_1950}.

En los años 60 y 70, el esfuerzo principal estaba en la traducción automática, como los esfuerzos del proyecto
Georgetown~\cite{techreport_georgetown_1964}.

Con la introducción de la inteligencia artificial (IA) en la década de 1980, surgieron métodos basados primero en reglas
y luego en modelos estadísticos, culminando con el desarrollo de modelos de aprendizaje
automático~\cite{article_manning_1999} en la década de 1990.

El verdadero cambio paradigmático llegó con el advenimiento de las redes neuronales y el aprendizaje profundo en la
década de 2010.
Este período vio la creación de modelos de lenguaje avanzados~\cite{article_devlin_2019}, que han revolucionado la
capacidad de las máquinas para procesar el lenguaje con un grado de sutileza y profundidad sin precedentes.
